{"cells":[{"cell_type":"markdown","metadata":{"id":"lqt_yzRy16Wj"},"source":["## Compulsory Task \n","\n","In this compulsory task you will clean the country column and parse the date column in the **store_income_data_task.csv** file."]},{"cell_type":"code","execution_count":2,"metadata":{"id":"vBP3WN2O16Wp"},"outputs":[{"name":"stderr","output_type":"stream","text":["c:\\Users\\AMMAR\\anaconda3\\Lib\\site-packages\\fuzzywuzzy\\fuzz.py:11: UserWarning: Using slow pure-python SequenceMatcher. Install python-Levenshtein to remove this warning\n","  warnings.warn('Using slow pure-python SequenceMatcher. Install python-Levenshtein to remove this warning')\n"]}],"source":["# Load up store_income_data.csv\n","import pandas as pd\n","from datetime import datetime\n","import fuzzywuzzy\n","from fuzzywuzzy import process\n","import chardet"]},{"cell_type":"markdown","metadata":{"id":"ItqLwumA16Wr"},"source":["1. Take a look at all the unique values in the \"country\" column. Then, convert the column to lowercase and remove any trailing white spaces."]},{"cell_type":"code","execution_count":3,"metadata":{"id":"sLkzt4Hr16Wr"},"outputs":[{"data":{"text/plain":["array(['united states/', 'britain', ' united states', 'britain/',\n","       ' united kingdom', 'u.k.', 'sa ', 'u.k/', 'america',\n","       'united kingdom', nan, 'united states', ' s.a.', 'england ', 'uk',\n","       's.a./', 'england', 'u.k', 'u.k ', 'america/', 'sa.', 's.a. ', ' ',\n","       'uk.', 'england/', ' britain', 'united states of america', 'uk/',\n","       'sa/', 'sa', 'england.', 'america.', 's.a..', 's.a.', ' u.k',\n","       ' united states of america', 'britain ', ' sa',\n","       'united states of america.', 'united states of america/',\n","       'united states.', 's. africasouth africa', ' england',\n","       'united kingdom ', 'united states of america ', ' uk', 'america ',\n","       ' s. africasouth africa', 'britain.', '/', 'united kingdom.',\n","       ' america', 'uk ', 'united states ', 's. africasouth africa/',\n","       'united kingdom/', 's. africasouth africa ',\n","       's. africasouth africa.', '.'], dtype=object)"]},"execution_count":3,"metadata":{},"output_type":"execute_result"}],"source":["df= pd.read_csv('store_income_data_task.csv')\n","df['country']=df['country'].str.lower()\n","df['country'].unique()"]},{"cell_type":"code","execution_count":4,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["There are 59 unique countries\n"]},{"data":{"text/plain":["array(['united states/', 'britain', ' united states', 'britain/',\n","       ' united kingdom', 'u.k.', 'sa ', 'u.k/', 'america',\n","       'united kingdom', nan, 'united states', ' s.a.', 'england ', 'uk',\n","       's.a./', 'england', 'u.k', 'u.k ', 'america/', 'sa.', 's.a. ', ' ',\n","       'uk.', 'england/', ' britain', 'united states of america', 'uk/',\n","       'sa/', 'sa', 'england.', 'america.', 's.a..', 's.a.', ' u.k',\n","       ' united states of america', 'britain ', ' sa',\n","       'united states of america.', 'united states of america/',\n","       'united states.', 's. africasouth africa', ' england',\n","       'united kingdom ', 'united states of america ', ' uk', 'america ',\n","       ' s. africasouth africa', 'britain.', '/', 'united kingdom.',\n","       ' america', 'uk ', 'united states ', 's. africasouth africa/',\n","       'united kingdom/', 's. africasouth africa ',\n","       's. africasouth africa.', '.'], dtype=object)"]},"execution_count":4,"metadata":{},"output_type":"execute_result"}],"source":["df['country'].str.strip()\n","countries = df['country'].unique()\n","print(f\"There are {len(countries)} unique countries\")\n","countries"]},{"cell_type":"code","execution_count":5,"metadata":{},"outputs":[{"data":{"text/plain":["[('uk', 100),\n"," ('uk.', 100),\n"," ('uk/', 100),\n"," (' uk', 100),\n"," ('uk ', 100),\n"," ('u.k.', 40),\n"," ('u.k/', 40),\n"," ('u.k', 40),\n"," ('u.k ', 40),\n"," (' u.k', 40)]"]},"execution_count":5,"metadata":{},"output_type":"execute_result"}],"source":["matches = fuzzywuzzy.process.extract(\"uk\", countries, limit=10, scorer=fuzzywuzzy.fuzz.token_sort_ratio)\n","matches"]},{"cell_type":"markdown","metadata":{"id":"P6dcDc4P16Ws"},"source":["2. Note that there should only be three separate countries. Eliminate all variations, so that 'South Africa', 'United Kingdom' and 'United States' are the only three countries."]},{"cell_type":"code","execution_count":6,"metadata":{"id":"qeV3CxMR16Ws"},"outputs":[{"data":{"text/plain":["array(['united states/', 'britain', ' united states', 'britain/',\n","       ' united kingdom', 'u.k.', 'sa ', 'u.k/', 'america',\n","       'united kingdom', nan, 'united states', ' s.a.', 'england ', 'uk',\n","       's.a./', 'england', 'u.k', 'u.k ', 'america/', 'sa.', 's.a. ', ' ',\n","       'uk.', 'england/', ' britain', 'united states of america', 'uk/',\n","       'sa/', 'sa', 'england.', 'america.', 's.a..', 's.a.', ' u.k',\n","       ' united states of america', 'britain ', ' sa',\n","       'united states of america.', 'united states of america/',\n","       'united states.', 's. africasouth africa', ' england',\n","       'united kingdom ', 'united states of america ', ' uk', 'america ',\n","       ' s. africasouth africa', 'britain.', '/', 'united kingdom.',\n","       ' america', 'uk ', 'united states ', 's. africasouth africa/',\n","       'united kingdom/', 's. africasouth africa ',\n","       's. africasouth africa.', '.'], dtype=object)"]},"execution_count":6,"metadata":{},"output_type":"execute_result"}],"source":["# without fuzzywuzzy\n","'''\n","df['country'] = df['country'].replace({'usa': 'united states', 'us': 'united states','uk': 'united kingdom', 'u.k': 'united kingdom',\n","                                       'sa.': 'south africa','s. africasouth africa/': 'south africa','s.a./':'south africa',\n","                                       'united states/':'united states','u.k/':'united kingdom','united states of america':'united states',\n","                                       'britain.':'united kingdom','s.a..':'south africa','britain':'united kingdom','britain/':'united kingdom',\n","                                       'england':'united kingdom','america':'united states','.':None,' ':None,'/':None})\n","'''\n","def replace_matches_in_column(df, column, string_to_match, min_ratio = 90):\n","    # get a list of unique strings\n","    strings = df[column].unique()\n","    \n","    # Get the top 10 closest matches to our input string\n","    matches = fuzzywuzzy.process.extract(string_to_match, strings, limit=10, scorer=fuzzywuzzy.fuzz.token_sort_ratio)\n","\n","    # Only get matches with a ratio > 90\n","    close_matches = [matches[0] for matches in matches if matches[1] >= min_ratio]\n","\n","    # Get the rows of all the close matches in our dataframe\n","    rows_with_matches = df[column].isin(close_matches)\n","\n","    # Replace all rows with close matches with the input matches \n","    df.loc[rows_with_matches, column] = string_to_match\n","    \n","    # Let us know when the function is done\n","    print(\"All done!\")\n","df['country'].unique()"]},{"cell_type":"code","execution_count":7,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["All done!\n","All done!\n","All done!\n","All done!\n","All done!\n","All done!\n","All done!\n","All done!\n"]},{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>id</th>\n","      <th>store_name</th>\n","      <th>store_email</th>\n","      <th>department</th>\n","      <th>income</th>\n","      <th>date_measured</th>\n","      <th>country</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>1</td>\n","      <td>Cullen/Frost Bankers, Inc.</td>\n","      <td>NaN</td>\n","      <td>Clothing</td>\n","      <td>$54438554.24</td>\n","      <td>4-2-2006</td>\n","      <td>united states</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>2</td>\n","      <td>Nordson Corporation</td>\n","      <td>NaN</td>\n","      <td>Tools</td>\n","      <td>$41744177.01</td>\n","      <td>4-1-2006</td>\n","      <td>britain</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>3</td>\n","      <td>Stag Industrial, Inc.</td>\n","      <td>NaN</td>\n","      <td>Beauty</td>\n","      <td>$36152340.34</td>\n","      <td>12-9-2003</td>\n","      <td>united states</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>4</td>\n","      <td>FIRST REPUBLIC BANK</td>\n","      <td>ecanadine3@fc2.com</td>\n","      <td>Automotive</td>\n","      <td>$8928350.04</td>\n","      <td>8-5-2006</td>\n","      <td>britain</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>5</td>\n","      <td>Mercantile Bank Corporation</td>\n","      <td>NaN</td>\n","      <td>Baby</td>\n","      <td>$33552742.32</td>\n","      <td>21-1-1973</td>\n","      <td>united kingdom</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>995</th>\n","      <td>996</td>\n","      <td>Columbia Sportswear Company</td>\n","      <td>cschooleyrn@sohu.com</td>\n","      <td>Automotive</td>\n","      <td>$52593924.99</td>\n","      <td>7-10-2005</td>\n","      <td>s. africasouth africa/</td>\n","    </tr>\n","    <tr>\n","      <th>996</th>\n","      <td>997</td>\n","      <td>WisdomTree Interest Rate Hedged High Yield Bon...</td>\n","      <td>NaN</td>\n","      <td>Electronics</td>\n","      <td>$60473676.46</td>\n","      <td>19-12-1990</td>\n","      <td>united states</td>\n","    </tr>\n","    <tr>\n","      <th>997</th>\n","      <td>998</td>\n","      <td>Tortoise Energy Infrastructure Corporation</td>\n","      <td>cbeardshallrp@ow.ly</td>\n","      <td>Health</td>\n","      <td>$1697293.64</td>\n","      <td>25-4-2009</td>\n","      <td>united states of america</td>\n","    </tr>\n","    <tr>\n","      <th>998</th>\n","      <td>999</td>\n","      <td>Qwest Corporation</td>\n","      <td>NaN</td>\n","      <td>Beauty</td>\n","      <td>$30091863.73</td>\n","      <td>13-1-2011</td>\n","      <td>england</td>\n","    </tr>\n","    <tr>\n","      <th>999</th>\n","      <td>1000</td>\n","      <td>SLM Corporation</td>\n","      <td>NaN</td>\n","      <td>Kids</td>\n","      <td>$66106336.48</td>\n","      <td>1-12-2011</td>\n","      <td>united kingdom</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>1000 rows × 7 columns</p>\n","</div>"],"text/plain":["       id                                         store_name  \\\n","0       1                         Cullen/Frost Bankers, Inc.   \n","1       2                                Nordson Corporation   \n","2       3                              Stag Industrial, Inc.   \n","3       4                                FIRST REPUBLIC BANK   \n","4       5                        Mercantile Bank Corporation   \n","..    ...                                                ...   \n","995   996                        Columbia Sportswear Company   \n","996   997  WisdomTree Interest Rate Hedged High Yield Bon...   \n","997   998         Tortoise Energy Infrastructure Corporation   \n","998   999                                  Qwest Corporation   \n","999  1000                                    SLM Corporation   \n","\n","              store_email   department        income date_measured  \\\n","0                     NaN     Clothing  $54438554.24      4-2-2006   \n","1                     NaN        Tools  $41744177.01      4-1-2006   \n","2                     NaN       Beauty  $36152340.34     12-9-2003   \n","3      ecanadine3@fc2.com   Automotive   $8928350.04      8-5-2006   \n","4                     NaN         Baby  $33552742.32     21-1-1973   \n","..                    ...          ...           ...           ...   \n","995  cschooleyrn@sohu.com   Automotive  $52593924.99     7-10-2005   \n","996                   NaN  Electronics  $60473676.46    19-12-1990   \n","997   cbeardshallrp@ow.ly       Health   $1697293.64     25-4-2009   \n","998                   NaN       Beauty  $30091863.73     13-1-2011   \n","999                   NaN         Kids  $66106336.48     1-12-2011   \n","\n","                      country  \n","0               united states  \n","1                     britain  \n","2               united states  \n","3                     britain  \n","4              united kingdom  \n","..                        ...  \n","995    s. africasouth africa/  \n","996             united states  \n","997  united states of america  \n","998                   england  \n","999            united kingdom  \n","\n","[1000 rows x 7 columns]"]},"execution_count":7,"metadata":{},"output_type":"execute_result"}],"source":["replace_matches_in_column(df=df, column='country', string_to_match=\"south africa\")\n","replace_matches_in_column(df=df, column='country', string_to_match=\"united kingdom\")\n","replace_matches_in_column(df=df, column='country', string_to_match=\"britain\")\n","replace_matches_in_column(df=df, column='country', string_to_match=\"united states\")\n","replace_matches_in_column(df=df, column='country', string_to_match=\"uk\")\n","replace_matches_in_column(df=df, column='country', string_to_match=\"us\")\n","replace_matches_in_column(df=df, column='country', string_to_match=\"united states of america\")\n","replace_matches_in_column(df=df, column='country', string_to_match=\"sa\")\n","df"]},{"cell_type":"code","execution_count":8,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["There are 35 unique countries\n"]},{"data":{"text/plain":["array(['united states', 'britain', 'united kingdom', 'u.k.', 'sa', 'u.k/',\n","       'america', nan, ' s.a.', 'england ', 'uk', 's.a./', 'england',\n","       'u.k', 'u.k ', 'america/', 's.a. ', ' ', 'england/',\n","       'united states of america', 'england.', 'america.', 's.a..',\n","       's.a.', ' u.k', 's. africasouth africa', ' england', 'america ',\n","       ' s. africasouth africa', '/', ' america',\n","       's. africasouth africa/', 's. africasouth africa ',\n","       's. africasouth africa.', '.'], dtype=object)"]},"execution_count":8,"metadata":{},"output_type":"execute_result"}],"source":["countries = df['country'].unique()\n","\n","print(f\"There are {len(countries)} unique countries\")\n","countries\n"]},{"cell_type":"code","execution_count":32,"metadata":{},"outputs":[{"data":{"text/plain":["array(['united states', 'united kingdom', 'south africa', nan, None],\n","      dtype=object)"]},"execution_count":32,"metadata":{},"output_type":"execute_result"}],"source":["df.replace('uk', 'united kingdom', inplace=True)\n","df.replace('united states of america', 'united states', inplace=True)\n","df.replace('britain', 'united kingdom', inplace=True)\n","df.replace('us', 'united states', inplace=True)\n","df.replace('sa', 'south africa', inplace=True)\n","df.replace('america.', 'united states', inplace=True) \n","df.replace('u.k.', 'united kingdom', inplace=True)\n","df.replace('u.k/', 'united kingdom', inplace=True)\n","df.replace('u.k', 'united kingdom', inplace=True)\n","df.replace(' u.k', 'united kingdom', inplace=True)\n","df.replace('u.k ', 'united kingdom', inplace=True)\n","df.replace('england', 'united kingdom', inplace=True)\n","df.replace('england/', 'united kingdom', inplace=True)\n","df.replace('england.', 'united kingdom', inplace=True)\n","df.replace(' england', 'united kingdom', inplace=True)\n","df.replace('england ', 'united kingdom', inplace=True)\n","df.replace('s.a.', 'south africa', inplace=True)\n","df.replace('s.a./', 'south africa', inplace=True)\n","df.replace('s.a..', 'south africa', inplace=True)\n","df.replace('s.a.', 'south africa', inplace=True)\n","df.replace('s.a.', 'south africa', inplace=True)\n","df.replace('s.a.', 'south africa', inplace=True)\n","df.replace('s. africasouth africa', 'south africa', inplace=True)\n","df.replace('s. africasouth africa/', 'south africa', inplace=True)\n","df.replace('s. africasouth africa ', 'south africa', inplace=True)\n","df.replace('s. africasouth africa.', 'south africa', inplace=True)\n","df.replace('s. africasouth africa', 'south africa', inplace=True)\n","df.replace(' s.a.', 'south africa', inplace=True)\n","df.replace(' s. africasouth africa', 'south africa', inplace=True)\n","df.replace('s.a. ', 'south africa', inplace=True)\n","df.replace('america', 'united states', inplace=True)\n","df.replace('america/', 'united states', inplace=True)\n","df.replace('america ', 'united states', inplace=True)\n","df.replace(' america', 'united states', inplace=True)\n","df.replace(' ', None, inplace=True)\n","df.replace('/', None, inplace=True)\n","df.replace('.', None, inplace=True)\n","df['country'].unique()"]},{"cell_type":"markdown","metadata":{"id":"UJZDMTwP16Ws"},"source":["3. Create a new column called `days_ago` in the DataFrame that is a copy of the 'date_measured' column but instead it is a number that shows how many days ago it was measured from the current date. Note that the current date can be obtained using `datetime.date.today()`."]},{"cell_type":"code","execution_count":31,"metadata":{"id":"gMJbN84P16Wt"},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>id</th>\n","      <th>store_name</th>\n","      <th>store_email</th>\n","      <th>department</th>\n","      <th>income</th>\n","      <th>date_measured</th>\n","      <th>country</th>\n","      <th>days_ago</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>1</td>\n","      <td>Cullen/Frost Bankers, Inc.</td>\n","      <td>NaN</td>\n","      <td>Clothing</td>\n","      <td>$54438554.24</td>\n","      <td>2006-02-04</td>\n","      <td>united states</td>\n","      <td>6663</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>2</td>\n","      <td>Nordson Corporation</td>\n","      <td>NaN</td>\n","      <td>Tools</td>\n","      <td>$41744177.01</td>\n","      <td>2006-01-04</td>\n","      <td>united kingdom</td>\n","      <td>6694</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>3</td>\n","      <td>Stag Industrial, Inc.</td>\n","      <td>NaN</td>\n","      <td>Beauty</td>\n","      <td>$36152340.34</td>\n","      <td>2003-09-12</td>\n","      <td>united states</td>\n","      <td>7539</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>4</td>\n","      <td>FIRST REPUBLIC BANK</td>\n","      <td>ecanadine3@fc2.com</td>\n","      <td>Automotive</td>\n","      <td>$8928350.04</td>\n","      <td>2006-05-08</td>\n","      <td>united kingdom</td>\n","      <td>6570</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>5</td>\n","      <td>Mercantile Bank Corporation</td>\n","      <td>NaN</td>\n","      <td>Baby</td>\n","      <td>$33552742.32</td>\n","      <td>1973-01-21</td>\n","      <td>united kingdom</td>\n","      <td>18730</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>995</th>\n","      <td>996</td>\n","      <td>Columbia Sportswear Company</td>\n","      <td>cschooleyrn@sohu.com</td>\n","      <td>Automotive</td>\n","      <td>$52593924.99</td>\n","      <td>2005-10-07</td>\n","      <td>south africa</td>\n","      <td>6783</td>\n","    </tr>\n","    <tr>\n","      <th>996</th>\n","      <td>997</td>\n","      <td>WisdomTree Interest Rate Hedged High Yield Bon...</td>\n","      <td>NaN</td>\n","      <td>Electronics</td>\n","      <td>$60473676.46</td>\n","      <td>1990-12-19</td>\n","      <td>united states</td>\n","      <td>12189</td>\n","    </tr>\n","    <tr>\n","      <th>997</th>\n","      <td>998</td>\n","      <td>Tortoise Energy Infrastructure Corporation</td>\n","      <td>cbeardshallrp@ow.ly</td>\n","      <td>Health</td>\n","      <td>$1697293.64</td>\n","      <td>2009-04-25</td>\n","      <td>united states</td>\n","      <td>5487</td>\n","    </tr>\n","    <tr>\n","      <th>998</th>\n","      <td>999</td>\n","      <td>Qwest Corporation</td>\n","      <td>NaN</td>\n","      <td>Beauty</td>\n","      <td>$30091863.73</td>\n","      <td>2011-01-13</td>\n","      <td>united kingdom</td>\n","      <td>4859</td>\n","    </tr>\n","    <tr>\n","      <th>999</th>\n","      <td>1000</td>\n","      <td>SLM Corporation</td>\n","      <td>NaN</td>\n","      <td>Kids</td>\n","      <td>$66106336.48</td>\n","      <td>2011-12-01</td>\n","      <td>united kingdom</td>\n","      <td>4537</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>1000 rows × 8 columns</p>\n","</div>"],"text/plain":["       id                                         store_name  \\\n","0       1                         Cullen/Frost Bankers, Inc.   \n","1       2                                Nordson Corporation   \n","2       3                              Stag Industrial, Inc.   \n","3       4                                FIRST REPUBLIC BANK   \n","4       5                        Mercantile Bank Corporation   \n","..    ...                                                ...   \n","995   996                        Columbia Sportswear Company   \n","996   997  WisdomTree Interest Rate Hedged High Yield Bon...   \n","997   998         Tortoise Energy Infrastructure Corporation   \n","998   999                                  Qwest Corporation   \n","999  1000                                    SLM Corporation   \n","\n","              store_email   department        income date_measured  \\\n","0                     NaN     Clothing  $54438554.24    2006-02-04   \n","1                     NaN        Tools  $41744177.01    2006-01-04   \n","2                     NaN       Beauty  $36152340.34    2003-09-12   \n","3      ecanadine3@fc2.com   Automotive   $8928350.04    2006-05-08   \n","4                     NaN         Baby  $33552742.32    1973-01-21   \n","..                    ...          ...           ...           ...   \n","995  cschooleyrn@sohu.com   Automotive  $52593924.99    2005-10-07   \n","996                   NaN  Electronics  $60473676.46    1990-12-19   \n","997   cbeardshallrp@ow.ly       Health   $1697293.64    2009-04-25   \n","998                   NaN       Beauty  $30091863.73    2011-01-13   \n","999                   NaN         Kids  $66106336.48    2011-12-01   \n","\n","            country  days_ago  \n","0     united states      6663  \n","1    united kingdom      6694  \n","2     united states      7539  \n","3    united kingdom      6570  \n","4    united kingdom     18730  \n","..              ...       ...  \n","995    south africa      6783  \n","996   united states     12189  \n","997   united states      5487  \n","998  united kingdom      4859  \n","999  united kingdom      4537  \n","\n","[1000 rows x 8 columns]"]},"execution_count":31,"metadata":{},"output_type":"execute_result"}],"source":["df['date_measured'] = pd.to_datetime(df['date_measured'], format='%d-%m-%Y')\n","today = pd.to_datetime(datetime.today().strftime('%Y-%m-%d'))\n","df['days_ago'] = (today - df['date_measured']).dt.days\n","df"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]}],"metadata":{"colab":{"provenance":[]},"kernelspec":{"display_name":"Python 3.10.0 ('phd')","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.7"},"vscode":{"interpreter":{"hash":"63d17dc58a06b6a6d4136fb13c245dafcf53668da37b1c3052c24d689135f5bb"}}},"nbformat":4,"nbformat_minor":0}
